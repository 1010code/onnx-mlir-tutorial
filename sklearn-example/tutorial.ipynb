{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562f5a16-835d-4517-bedc-2aa15b5bda49",
   "metadata": {},
   "source": [
    "## ONNX-MLIR\n",
    "透過一個實作範例將一個鳶尾花朵邏輯迴歸分類器onnx轉換輸出動態連結庫(so)並使用C++進行推論。\n",
    "\n",
    "### 準備鳶尾花邏輯回歸分類器的 ONNX 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5282405-e6bf-4bbb-aea9-5adfa7351132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=1000))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 載入鳶尾花資料集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型Pipeline：標準化 + 邏輯迴歸\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da65a942-c764-4c6b-bbed-813d00ec51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# 定義輸入類型\n",
    "initial_type = [('float_input', FloatTensorType([None, X.shape[1]]))]\n",
    "\n",
    "# 轉換為 ONNX 模型\n",
    "onnx_model = convert_sklearn(model, initial_types=initial_type, target_opset=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afb752-fe98-435f-a2c0-efe30ed2ee55",
   "metadata": {},
   "source": [
    "### 使用 Hummingbird 將模型轉換為 ONNX 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b26da0-0c0d-4103-97dc-ebf902a47ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install onnxruntime==1.19.2 onnx==1.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75efcac-0b6c-4c66-a248-40349081498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with digest: 1609dbcba26491d9bb02bec919f95901ba2140e5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1609dbcba26491d9bb02bec919f95901ba2140e5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hummingbird.ml import convert\n",
    "\n",
    "# 將 scikit-learn 模型轉換為 ONNX 格式\n",
    "hb_model = convert(onnx_model, 'onnx')\n",
    "\n",
    "# 保存轉換後的 ONNX 模型\n",
    "hb_model.save('iris_logistic_regression_torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849c707-93be-4791-908a-7989d3da114a",
   "metadata": {},
   "source": [
    "### 使用 ONNX-MLIR 將模型編譯轉換為動態連結庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a60184-7b15-47c3-95d7-22340cd7155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  iris_logistic_regression_torch.zip\n",
      "  inflating: dist/container.pkl      \n",
      "  inflating: dist/deploy_model.onnx  \n",
      "  inflating: dist/model_configuration.txt  \n",
      "  inflating: dist/model_type.txt     \n",
      "[1/6] Sat Nov 16 11:50:02 2024 (0s) Importing ONNX Model to MLIR Module from \"deploy_model.onnx\"\n",
      "[2/6] Sat Nov 16 11:50:02 2024 (0s) Compiling and Optimizing MLIR Module\n",
      "[3/6] Sat Nov 16 11:50:02 2024 (0s) Translating MLIR Module to LLVM and Generating LLVM Optimized Bitcode\n",
      "[4/6] Sat Nov 16 11:50:02 2024 (0s) Generating Object from LLVM Bitcode\n",
      "[5/6] Sat Nov 16 11:50:03 2024 (1s) Linking and Generating the Output Shared Library\n",
      "[6/6] Sat Nov 16 11:50:03 2024 (1s) Compilation completed\n"
     ]
    }
   ],
   "source": [
    "!unzip -o iris_logistic_regression_torch.zip -d dist\n",
    "!../onnx-mlir/Release/bin/onnx-mlir --EmitLib dist/deploy_model.onnx "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa986e-af75-4cfd-8faa-302836b7d373",
   "metadata": {},
   "source": [
    "### 編寫 C++ 程式以載入並執行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "036db295-6125-4b96-8dfe-66dbd4038a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型输出：2.48873e-05 0.00856126 0.991414 \n"
     ]
    }
   ],
   "source": [
    "!g++ --std=c++17 inference.cpp dist/deploy_model.so -o main -I../onnx-mlir/include\n",
    "!./main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b062bf8d-9681-4fa4-890b-d723fffa0e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld: warning: platform not specified\n",
      "ld: warning: -arch not specified\n",
      "ld: warning: No platform min-version specified on command line\n",
      "ld: warning: ignoring file dist/deploy_model.so, building for -unknown but attempting to link with file built for macOS-x86_64\n",
      "Undefined symbols for architecture unknown:\n",
      "  \"_main\", referenced from:\n",
      "     implicit entry/start for main executable\n",
      "ld: symbol(s) not found for architecture unknown\n"
     ]
    }
   ],
   "source": [
    "!ld dist/deploy_model.so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8651b7d-7b38-485c-b178-c866abd5461d",
   "metadata": {},
   "source": [
    "## TVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f8b96-d070-4450-8af9-d0f1b20112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apache-tvm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64686a11-ae63-4ed1-9361-51794a39315a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "162ab7d4-2278-4ff8-a0e6-0a9f2e0f8833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import helper\n",
    "\n",
    "# 載入已轉換的 ONNX 模型\n",
    "onnx_model = onnx.load('dist/deploy_model.onnx')\n",
    "\n",
    "# 修改輸入張量的形狀\n",
    "# 假設輸入張量名稱為 \"input\" 且目標形狀為 [1, 4]\n",
    "for input in model.graph.input:\n",
    "    input.type.tensor_type.shape.dim[0].dim_value = 1\n",
    "    input.type.tensor_type.shape.dim[1].dim_value = 4\n",
    "# 推斷模型形狀以應用變更\n",
    "model = shape_inference.infer_shapes(model)\n",
    "# 保存修改過的 ONNX 模型\n",
    "onnx.save(model, 'iris_logistic_regression_fixed.onnx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "33e182d1-0a50-452d-9e9d-537feebc02e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inputs:\n",
      "Name: float_input, Shape: [1, 4]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# 載入 ONNX 模型\n",
    "model = onnx.load(\"iris_logistic_regression_fixed.onnx\")\n",
    "print(\"Model inputs:\")\n",
    "for input in model.graph.input:\n",
    "    print(f\"Name: {input.name}, Shape: {[dim.dim_value if dim.dim_value > 0 else '?' for dim in input.type.tensor_type.shape.dim]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fa8260c6-a54b-4c6d-b186-0fb3a0c17008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "[21:44:46] /Users/runner/work/tlcpack/tlcpack/tvm/src/te/schedule/bound.cc:119: not in feed graph consumer = compute(p0_red_temp, body=[reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=0), reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=1)], axis=[iter_var(ax0, range(min=0, ext=1))], reduce_axis=[iter_var(k1, range(min=0, ext=3))], tag=comm_reduce_idx, attrs={})\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/bin/tvmc\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/driver/tvmc/main.py\", line 115, in main\n",
      "    sys.exit(_main(sys.argv[1:]))\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/driver/tvmc/main.py\", line 103, in _main\n",
      "    return args.func(args)\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/driver/tvmc/compiler.py\", line 180, in drive_compile\n",
      "    compile_model(\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/driver/tvmc/compiler.py\", line 353, in compile_model\n",
      "    graph_module = build(\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/driver/tvmc/compiler.py\", line 428, in build\n",
      "    return relay.build(\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/relay/build_module.py\", line 364, in build\n",
      "    graph_json, runtime_mod, params = bld_mod.build(\n",
      "  File \"/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/relay/build_module.py\", line 161, in build\n",
      "    self._build(\n",
      "  File \"tvm/_ffi/_cython/./packed_func.pxi\", line 331, in tvm._ffi._cy3.core.PackedFuncBase.__call__\n",
      "  File \"tvm/_ffi/_cython/./packed_func.pxi\", line 276, in tvm._ffi._cy3.core.FuncCall\n",
      "  File \"tvm/_ffi/_cython/./base.pxi\", line 181, in tvm._ffi._cy3.core.CHECK_CALL\n",
      "tvm._ffi.base.TVMError: Traceback (most recent call last):\n",
      "  [bt] (8) 9   libtvm.dylib                        0x000000012852cecf tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>*)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>*) const + 303\n",
      "  [bt] (7) 8   libtvm.dylib                        0x0000000129543973 tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*) + 563\n",
      "  [bt] (6) 7   libtvm.dylib                        0x0000000129539c89 tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&) + 201\n",
      "  [bt] (5) 6   libtvm.dylib                        0x0000000129547768 tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) const + 312\n",
      "  [bt] (4) 5   libtvm.dylib                        0x000000012953bc26 void tvm::codegen::PrintBinaryExpr<tvm::tir::AddNode>(tvm::tir::AddNode const*, char const*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&, tvm::codegen::CodeGenC*) + 614\n",
      "  [bt] (3) 4   libtvm.dylib                        0x0000000129547768 tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) const + 312\n",
      "  [bt] (2) 3   libtvm.dylib                        0x000000012953f352 tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) + 1314\n",
      "  [bt] (1) 2   libtvm.dylib                        0x00000001284d63f9 tvm::runtime::detail::LogFatal::Entry::Finalize() + 89\n",
      "  [bt] (0) 1   libtvm.dylib                        0x000000012a295038 tvm::runtime::Backtrace() + 24\n",
      "  File \"/Users/runner/work/tlcpack/tlcpack/tvm/src/target/source/codegen_c.cc\", line 608\n",
      "TVMError: Unresolved call Op(tir.fabs)\n"
     ]
    }
   ],
   "source": [
    "!tvmc compile iris_logistic_regression_fixed.onnx --target=\"c\" --output model.tar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230bf562-d2d9-4823-b647-5a86a785c8fc",
   "metadata": {},
   "source": [
    "### 使用 Scikit-learn 訓練邏輯回歸模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "079a0de3-21ff-462e-992c-7afd1eb82b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 載入鳶尾花資料集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 建立模型Pipeline：標準化 + 邏輯迴歸\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    # ('classifier', LogisticRegression(max_iter=1000))\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "# model = LogisticRegression(max_iter=1000)\n",
    "# 訓練模型\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea41aa1-81d7-45b3-bca1-0de7fc47a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# 定義輸入類型\n",
    "initial_type = [('float_input', FloatTensorType([None, X.shape[1]]))]\n",
    "\n",
    "# 轉換為 ONNX 模型\n",
    "onnx_model = convert_sklearn(model, initial_types=initial_type, target_opset=9)\n",
    "\n",
    "# 儲存ONNX模型\n",
    "with open(\"iris_logistic_regression.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c6452c-a5b3-4417-9150-779056f927b7",
   "metadata": {},
   "source": [
    "### 使用 Hummingbird 將模型轉換為 ONNX/TVM 格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c93704-5de8-42ae-b173-c651f5ee513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "[21:55:16] /Users/runner/work/tlcpack/tlcpack/tvm/src/te/schedule/bound.cc:119: not in feed graph consumer = compute(p0_red_temp, body=[reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=0), reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=1)], axis=[iter_var(ax0, range(min=0, ext=150))], reduce_axis=[iter_var(k1, range(min=0, ext=3))], tag=comm_reduce_idx, attrs={})\n",
      "/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/contrib/graph_runtime.py:25: UserWarning: This function has been moved to tvm.contrib.graph_executor and will be removed in the next TVM release\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hummingbird.ml.containers.sklearn.tvm_containers.TVMSklearnContainerClassification at 0x1394000d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hummingbird.ml import convert\n",
    "\n",
    "# model_tvm = convert(model, backend=\"tvm\", test_input=X)\n",
    "model_tvm = convert(onnx_model, backend=\"tvm\", test_input=X)\n",
    "model_tvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed4ee46-f743-4089-8f1a-34fc9285752f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with digest: 7dc10ec35a1b17191d02c981934b6b41b8884137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7dc10ec35a1b17191d02c981934b6b41b8884137'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hummingbird.ml import convert\n",
    "\n",
    "# 將 scikit-learn 模型轉換為 ONNX 格式\n",
    "hb_model = convert(onnx_model, 'onnx')\n",
    "\n",
    "# 保存轉換後的 ONNX 模型\n",
    "hb_model.save('iris_logistic_regression_torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935d0af-0524-458c-9b77-12106ed592db",
   "metadata": {},
   "source": [
    "## 使用 TVM 將 ONNX 模型編譯為 C 程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642558ba-4e24-49d0-a0c8-0922e0296a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_LINKER=x86_64-linux-gnu-gcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40308bf-b78a-4deb-b362-06da95164506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:12:10] /Users/runner/work/tlcpack/tlcpack/tvm/src/te/schedule/bound.cc:119: not in feed graph consumer = compute(p0_red_temp, body=[reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=0), reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=1)], axis=[iter_var(ax0, range(min=0, ext=1))], reduce_axis=[iter_var(k1, range(min=0, ext=3))], tag=comm_reduce_idx, attrs={})\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import cc, utils\n",
    "from tvm.contrib import graph_executor\n",
    "import onnx\n",
    "import sys\n",
    "\n",
    "original_platform = sys.platform\n",
    "sys.platform = \"linux\"\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"dist/deploy_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 Relay 模型\n",
    "input_name = 'float_input'  # 輸入名稱可在 ONNX 模型中確認\n",
    "shape_dict = {input_name: (1, 4)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 設置目標架構，這裡假設為通用的 CPU\n",
    "# target = 'llvm'\n",
    "# target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-linux-gnu\")\n",
    "target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "# target = tvm.target.Target(\"llvm\", host=\"llvm -mtriple=x86_64-apple-darwin\")\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target, params=params)\n",
    "\n",
    "# 編譯輸出為 C 代碼\n",
    "# lib.export_library(\"output.so\", cc=\"x86_64-linux-gnu-gcc\")\n",
    "lib.export_library(\"output.so\", cc=\"aarch64-linux-gnu-gcc\")\n",
    "# lib.export_library(\"output.so\", cc=\"clang\")\n",
    "\n",
    "# 恢復原始平台\n",
    "sys.platform = original_platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8b638-df7f-41ef-a761-944348d89444",
   "metadata": {},
   "source": [
    "如果要在 macOS 跨平台編譯。在 macOS 上使用 TVM 的export_library函數時，預設會包含-undefined dynamic_lookup連結器標誌。會導致連結器報錯：\n",
    "> Command line: x86_64-linux-gnu-gcc -shared -fPIC -undefined dynamic_lookup -o output.so \n",
    "\n",
    "遇到的錯誤是由於 macOS 特有的連結器標誌 -undefineddynamic_lookup 被傳遞給了 Linux 交叉編譯器，導致編譯失敗。為了解決這個問題，可以暫時修改sys.platform，讓 TVM 認為正在 Linux 上執行：\n",
    "\n",
    "```py\n",
    "import sys\n",
    "\n",
    "original_platform = sys.platform\n",
    "sys.platform = \"linux\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de69962-ac91-4f92-aca2-44aa246ba968",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!g++ -std=c++17 -o main test.cpp \\\n",
    "    -I/Users/yilintsai/Documents/tvm/include \\\n",
    "    -I/Users/yilintsai/Documents/tvm/3rdparty/dlpack/include \\\n",
    "    -I/Users/yilintsai/Documents/tvm/3rdparty/dmlc-core/include \\\n",
    "    -ltvm_runtime -ldl -pthread \\\n",
    "    -Wno-macro-redefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f755cdc2-8aed-4939-a5ef-8066d21a05fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Label: 2\n",
      "Prediction Probabilities: [2.48873e-05, 0.00856126, 0.991414]\n"
     ]
    }
   ],
   "source": [
    "!./main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36910af5-eeeb-4e8c-843f-6b00242cd33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yilintsai/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/__init__.py\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import tvm; print(tvm.__file__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d6828-28f8-42f7-befb-42cd6bff87d0",
   "metadata": {},
   "source": [
    "#### 無法順利產so 因此直接使用TVM推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6374cda-4abf-4469-b313-c548e03f36a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "[22:00:42] /Users/runner/work/tlcpack/tlcpack/tvm/src/te/schedule/bound.cc:119: not in feed graph consumer = compute(p0_red_temp, body=[reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=0), reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=1)], axis=[iter_var(ax0, range(min=0, ext=1))], reduce_axis=[iter_var(k1, range(min=0, ext=3))], tag=comm_reduce_idx, attrs={})\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import graph_executor\n",
    "\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"dist/deploy_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 TVM 的 Relay 模型格式\n",
    "input_name = 'float_input'  # 確認模型的輸入名稱，可從 ONNX 模型中查看\n",
    "shape_dict = {input_name: (1, 4)}  # 定義輸入形狀 (1, 4) 代表輸入的形狀\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 設定編譯目標為 CPU 上的 LLVM (可以根據需求設為 \"cuda\" 或 \"opencl\" 等其他架構)\n",
    "target = \"llvm\"\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    # 編譯 Relay 模型，將其轉換為可以運行的格式\n",
    "    lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4f7d9a-3420-41a1-a1fc-9d3f2b17a398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4887262e-05 8.5612610e-03 9.9141383e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 使用 TVM 的 Graph Executor 模組來載入編譯後的模型\n",
    "module = graph_executor.GraphModule(lib[\"default\"](tvm.cpu(0)))\n",
    "\n",
    "# 定義輸入資料並設定模型輸入，這裡使用一筆測試資料\n",
    "input_data = np.array([[6.3, 3.3, 6. , 2.5]], dtype=np.float32)\n",
    "module.set_input(input_name, input_data)\n",
    "\n",
    "# 執行模型推理\n",
    "module.run()\n",
    "\n",
    "# 定義輸出形狀，這裡假設模型的輸出形狀為 (1, 1)\n",
    "output_shape = (1, 1)  # 可根據實際模型調整\n",
    "tvm_output = module.get_output(1).asnumpy()  # 獲取輸出並轉換為 NumPy 陣列\n",
    "\n",
    "# 輸出推理結果\n",
    "print(tvm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d9c8db6-7aa9-4f0a-93bd-66668b7fcc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (1,)\n"
     ]
    }
   ],
   "source": [
    "# 打印輸出形狀\n",
    "tvm_output = module.get_output(0).asnumpy()\n",
    "print(\"Output shape:\", tvm_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963aaa7-a130-439a-a8e1-7404d70ba4e3",
   "metadata": {},
   "source": [
    "### TVM 產 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ba976b-8197-4cad-a70f-31cc555617dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:17:30] /Users/runner/work/tlcpack/tlcpack/tvm/src/te/schedule/bound.cc:119: not in feed graph consumer = compute(p0_red_temp, body=[reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=0), reduce(combiner=comm_reducer(result=[select(((argmax_lhs_1 > argmax_rhs_1) || ((argmax_lhs_1 == argmax_rhs_1) && (argmax_lhs_0 < argmax_rhs_0))), argmax_lhs_0, argmax_rhs_0), select((argmax_lhs_1 > argmax_rhs_1), argmax_lhs_1, argmax_rhs_1)], lhs=[argmax_lhs_0, argmax_lhs_1], rhs=[argmax_rhs_0, argmax_rhs_1], identity_element=[-1, -3.40282e+38f]), source=[k1, p0[ax0, k1]], init=[], axis=[iter_var(k1, range(min=0, ext=3))], where=(bool)1, value_index=1)], axis=[iter_var(ax0, range(min=0, ext=1))], reduce_axis=[iter_var(k1, range(min=0, ext=3))], tag=comm_reduce_idx, attrs={})\n"
     ]
    },
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x00000001208f4ecf tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>*)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>*) const + 303\n  [bt] (7) 8   libtvm.dylib                        0x000000012190b973 tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*) + 563\n  [bt] (6) 7   libtvm.dylib                        0x0000000121901c89 tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&) + 201\n  [bt] (5) 6   libtvm.dylib                        0x000000012190f768 tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) const + 312\n  [bt] (4) 5   libtvm.dylib                        0x0000000121903c26 void tvm::codegen::PrintBinaryExpr<tvm::tir::AddNode>(tvm::tir::AddNode const*, char const*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&, tvm::codegen::CodeGenC*) + 614\n  [bt] (3) 4   libtvm.dylib                        0x000000012190f768 tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) const + 312\n  [bt] (2) 3   libtvm.dylib                        0x0000000121907352 tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) + 1314\n  [bt] (1) 2   libtvm.dylib                        0x000000012089e3f9 tvm::runtime::detail::LogFatal::Entry::Finalize() + 89\n  [bt] (0) 1   libtvm.dylib                        0x000000012265d038 tvm::runtime::Backtrace() + 24\n  File \"/Users/runner/work/tlcpack/tlcpack/tvm/src/target/source/codegen_c.cc\", line 608\nTVMError: Unresolved call Op(tir.fabs)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tvm\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mPassContext(opt_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# 編譯 Relay 模型\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     mod \u001b[38;5;241m=\u001b[39m relay\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mSimplifyInference()(mod)\n\u001b[0;32m---> 20\u001b[0m     lib \u001b[38;5;241m=\u001b[39m \u001b[43mrelay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 匯出模型為 C 程式碼\u001b[39;00m\n\u001b[1;32m     23\u001b[0m lib\u001b[38;5;241m.\u001b[39mexport_library(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.c\u001b[39m\u001b[38;5;124m\"\u001b[39m, cc\u001b[38;5;241m.\u001b[39mcreate_ccompiler())\n",
      "File \u001b[0;32m~/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/relay/build_module.py:364\u001b[0m, in \u001b[0;36mbuild\u001b[0;34m(ir_mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tophub_context:\n\u001b[1;32m    363\u001b[0m     bld_mod \u001b[38;5;241m=\u001b[39m BuildModule()\n\u001b[0;32m--> 364\u001b[0m     graph_json, runtime_mod, params \u001b[38;5;241m=\u001b[39m \u001b[43mbld_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mir_mod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkspace_memory_pools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkspace_memory_pools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconstant_memory_pools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstant_memory_pools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     func_metadata \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mget_function_metadata()\n\u001b[1;32m    375\u001b[0m     devices \u001b[38;5;241m=\u001b[39m bld_mod\u001b[38;5;241m.\u001b[39mget_devices()\n",
      "File \u001b[0;32m~/anaconda3/envs/onnx-mlir/lib/python3.10/site-packages/tvm/relay/build_module.py:161\u001b[0m, in \u001b[0;36mBuildModule.build\u001b[0;34m(self, mod, target, target_host, executor, runtime, workspace_memory_pools, constant_memory_pools, params, mod_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m autotvm\u001b[38;5;241m.\u001b[39mGLOBAL_SCOPE\u001b[38;5;241m.\u001b[39msilent \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    156\u001b[0m     is_auto_scheduler_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_meta_schedule_enabled() \u001b[38;5;129;01mor\u001b[39;00m old_autotvm_silent\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m mangle_module_name(mod_name)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_memory_pools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconstant_memory_pools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m autotvm\u001b[38;5;241m.\u001b[39mGLOBAL_SCOPE\u001b[38;5;241m.\u001b[39msilent \u001b[38;5;241m=\u001b[39m old_autotvm_silent\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Get artifacts\u001b[39;00m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:331\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.PackedFuncBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./packed_func.pxi:276\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mtvm/_ffi/_cython/./base.pxi:181\u001b[0m, in \u001b[0;36mtvm._ffi._cy3.core.CHECK_CALL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  [bt] (8) 9   libtvm.dylib                        0x00000001208f4ecf tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>*)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::StmtFunctor<void (tvm::tir::Stmt const&)>*) const + 303\n  [bt] (7) 8   libtvm.dylib                        0x000000012190b973 tvm::codegen::CodeGenC::VisitStmt_(tvm::tir::BufferStoreNode const*) + 563\n  [bt] (6) 7   libtvm.dylib                        0x0000000121901c89 tvm::codegen::CodeGenC::PrintExpr(tvm::PrimExpr const&) + 201\n  [bt] (5) 6   libtvm.dylib                        0x000000012190f768 tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) const + 312\n  [bt] (4) 5   libtvm.dylib                        0x0000000121903c26 void tvm::codegen::PrintBinaryExpr<tvm::tir::AddNode>(tvm::tir::AddNode const*, char const*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&, tvm::codegen::CodeGenC*) + 614\n  [bt] (3) 4   libtvm.dylib                        0x000000012190f768 tvm::NodeFunctor<void (tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>::operator()(tvm::runtime::ObjectRef const&, tvm::tir::ExprFunctor<void (tvm::PrimExpr const&, std::__1::basic_ostream<char, std::__1::char_traits<char>>&)>*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) const + 312\n  [bt] (2) 3   libtvm.dylib                        0x0000000121907352 tvm::codegen::CodeGenC::VisitExpr_(tvm::tir::CallNode const*, std::__1::basic_ostream<char, std::__1::char_traits<char>>&) + 1314\n  [bt] (1) 2   libtvm.dylib                        0x000000012089e3f9 tvm::runtime::detail::LogFatal::Entry::Finalize() + 89\n  [bt] (0) 1   libtvm.dylib                        0x000000012265d038 tvm::runtime::Backtrace() + 24\n  File \"/Users/runner/work/tlcpack/tlcpack/tvm/src/target/source/codegen_c.cc\", line 608\nTVMError: Unresolved call Op(tir.fabs)"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import cc\n",
    "import onnx\n",
    "\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"dist/deploy_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 Relay 模型\n",
    "input_name = 'float_input'\n",
    "shape_dict = {input_name: (1, 4)}\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 設置目標架構\n",
    "target = tvm.target.Target(\"c\")\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=1):\n",
    "    # 編譯 Relay 模型\n",
    "    mod = relay.transform.SimplifyInference()(mod)\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "# 匯出模型為 C 程式碼\n",
    "lib.export_library(\"model.c\", cc.create_ccompiler())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43fff27-45e7-4182-814c-1e65cef22be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib import cc, utils, graph_executor\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "# 載入 ONNX 模型\n",
    "onnx_model = onnx.load(\"dist/deploy_model.onnx\")\n",
    "\n",
    "# 將 ONNX 模型轉換為 Relay 模型\n",
    "input_name = 'float_input'  # 確認模型的輸入名稱\n",
    "shape_dict = {input_name: (1, 4)}  # 定義輸入形狀 (1, 4)\n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "# 設定編譯目標為 \"c\" 以生成 C 程式碼\n",
    "target = \"c\"\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "# # 儲存編譯的共享庫 (dylib 為 macOS 共享庫)\n",
    "# lib.export_library(\"logistic_regression_iris.so\", cc.create_shared, cc=\"g++\")\n",
    "# print(f\"共享庫已儲存\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01cb1ea0-1b5e-4299-9cdc-a8ed51333bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.export_library(\"c_model.tar\", cc.create_shared, cc=\"g++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae98f28-7c4b-4b2e-906d-2a4731843cb1",
   "metadata": {},
   "source": [
    "## 使用ONNX Runtime推論比對結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa57338-f3ec-4c89-9225-67b5b5f5e81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4887262e-05 8.5612610e-03 9.9141383e-01]]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# 加載 ONNX 模型\n",
    "session = ort.InferenceSession('dist/deploy_model.onnx')\n",
    "\n",
    "# 準備輸入資料\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_data = np.array([[6.3, 3.3, 6. , 2.5]], dtype=np.float32)\n",
    "\n",
    "# 進行推理\n",
    "pred_onnx = session.run(None, {input_name: input_data})[1]\n",
    "\n",
    "# 輸出預測結果\n",
    "print(pred_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8091b61-1312-4f18-989b-4165203b191f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
